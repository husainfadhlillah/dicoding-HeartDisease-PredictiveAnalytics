{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25fd4ab9",
   "metadata": {},
   "source": [
    "# **Proyek Predictive Analytics: Prediksi Penyakit Jantung**\n",
    "\n",
    "- **Nama:** Muhammad Husain Fadhlillah\n",
    "- **Email Student:** mc006d5y2343@student.devacademy.id\n",
    "- **Cohort ID:** MC006D5Y2343"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87872b8",
   "metadata": {},
   "source": [
    "## **1. Mengimpor Library yang Dibutuhkan**\n",
    "Langkah pertama adalah mengimpor semua library Python yang akan digunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ef413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengabaikan peringatan yang tidak relevan agar output lebih bersih\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Library untuk manipulasi dan analisis data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Library untuk visualisasi data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Library dari Scikit-learn untuk machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Mengatur agar plot ditampilkan inline di notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5773bd7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d9ba27b",
   "metadata": {},
   "source": [
    "## **2. Data Loading dan Understanding**\n",
    "Pada tahap ini, kita akan memuat dataset, yaitu \"Heart Failure Prediction\" dari file CSV yang diunggah. Dataset ini memiliki 918 sampel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd67d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat dataset dari file CSV\n",
    "# Pastikan file 'heart.csv' berada di direktori yang sama atau unggah ke environment Colab\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Menampilkan 5 baris pertama dari dataframe\n",
    "print(\"Data Awal (5 baris pertama):\")\n",
    "display(df.head())\n",
    "\n",
    "# Menampilkan informasi dasar dataframe untuk memahami tipe data dan non-null counts\n",
    "print(\"\\nInformasi DataFrame:\")\n",
    "df.info()\n",
    "\n",
    "# Variabel target kita adalah 'HeartDisease' (1: Gagal Jantung, 0: Sehat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78fd951",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b2d76d4",
   "metadata": {},
   "source": [
    "## **3. Exploratory Data Analysis (EDA)**\n",
    "Melakukan analisis dan visualisasi pada data untuk mendapatkan wawasan lebih dalam. Ini termasuk memeriksa distribusi fitur, keseimbangan kelas target, dan korelasi antar fitur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan statistik deskriptif untuk fitur numerik\n",
    "print(\"Statistik Deskriptif:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Memisahkan fitur numerik dan kategorikal untuk analisis lebih lanjut\n",
    "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Variabel target 'HeartDisease' adalah numerik (0 atau 1) jadi kita pindahkan dari categorical\n",
    "numerical_cols.remove('HeartDisease')\n",
    "\n",
    "print(f\"\\nFitur Numerik: {numerical_cols}\")\n",
    "print(f\"Fitur Kategorikal: {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f1f8a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi distribusi variabel target\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='HeartDisease', data=df)\n",
    "plt.title('Distribusi Variabel Target (0: Sehat, 1: Gagal Jantung)')\n",
    "plt.xlabel('Status Gagal Jantung')\n",
    "plt.ylabel('Jumlah Pasien')\n",
    "plt.show()\n",
    "print(df['HeartDisease'].value_counts())\n",
    "\n",
    "# Visualisasi distribusi fitur numerik\n",
    "df[numerical_cols].hist(figsize=(14, 10), bins=20)\n",
    "plt.suptitle('Distribusi Fitur Numerik')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n",
    "\n",
    "# Visualisasi distribusi fitur kategorikal\n",
    "plt.figure(figsize=(14, 12))\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    plt.subplot(3, 2, i + 1)\n",
    "    sns.countplot(x=col, data=df, hue='HeartDisease')\n",
    "    plt.title(f'Distribusi {col} berdasarkan Gagal Jantung')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Jumlah')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15371482",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb13008a",
   "metadata": {},
   "source": [
    "## **4. Data Cleaning & Preparation**\n",
    "\n",
    "Tahap ini meliputi:\n",
    "1. Pemisahan fitur dan target.\n",
    "2. Penanganan data duplikat.\n",
    "3. Pemisahan data menjadi set pelatihan dan pengujian.\n",
    "4. Pembuatan pipeline untuk preprocessing (standarisasi untuk numerik dan one-hot encoding untuk kategorikal).\n",
    "\n",
    "Catatan: Dataset ini tidak memiliki missing values, namun kita akan tetap memeriksa dan menangani data duplikat. Penanganan outlier tidak dilakukan karena distribusi data numerik cukup wajar dan dalam konteks medis, nilai ekstrem bisa jadi data valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89138e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memisahkan fitur (X) dan target (y)\n",
    "X = df.drop('HeartDisease', axis=1)\n",
    "y = df['HeartDisease']\n",
    "\n",
    "# Memeriksa dan menangani data duplikat\n",
    "print(f\"Jumlah data duplikat sebelum dihapus: {X.duplicated().sum()}\")\n",
    "if X.duplicated().sum() > 0:\n",
    "    # Simpan indeks data yang tidak duplikat\n",
    "    non_duplicate_indices = ~X.duplicated()\n",
    "    X = X[non_duplicate_indices]\n",
    "    y = y[non_duplicate_indices]\n",
    "    print(f\"Jumlah data duplikat setelah dihapus: {X.duplicated().sum()}\")\n",
    "\n",
    "print(f\"\\nUkuran data setelah dibersihkan: {X.shape}\")\n",
    "\n",
    "# Membagi data menjadi data latih (80%) dan data uji (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"\\nUkuran data latih: {X_train.shape}\")\n",
    "print(f\"Ukuran data uji: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afd2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat pipeline untuk preprocessing\n",
    "# Fitur numerik akan di-scale menggunakan StandardScaler\n",
    "# Fitur kategorikal akan di-encode menggunakan OneHotEncoder\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Membuat preprocessor dengan ColumnTransformer\n",
    "# Ini akan menerapkan transformer yang berbeda ke kolom yang berbeda\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough' # Kolom yang tidak disebutkan akan dilewatkan\n",
    ")\n",
    "\n",
    "# Menampilkan pipeline preprocessor\n",
    "print(\"Pipeline Preprocessing:\")\n",
    "display(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee58c3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0b79020",
   "metadata": {},
   "source": [
    "## **5. Modeling**\n",
    "Membangun, melatih, dan mengevaluasi dua model klasifikasi: Logistic Regression dan Random Forest. Akan mengintegrasikan preprocessor ke dalam pipeline model untuk memastikan data diproses dengan benar sebelum pelatihan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad858dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model 1: Logistic Regression ===\n",
    "\n",
    "# Membuat pipeline lengkap yang menggabungkan preprocessor dan model\n",
    "log_reg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Melatih model Logistic Regression menggunakan pipeline\n",
    "print(\"Melatih model Logistic Regression...\")\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "print(\"Model Logistic Regression berhasil dilatih.\\n\")\n",
    "\n",
    "\n",
    "# === Model 2: Random Forest ===\n",
    "\n",
    "# Membuat pipeline lengkap untuk Random Forest\n",
    "rand_forest_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42))\n",
    "])\n",
    "\n",
    "# Melatih model Random Forest menggunakan pipeline\n",
    "print(\"Melatih model Random Forest...\")\n",
    "rand_forest_pipeline.fit(X_train, y_train)\n",
    "print(\"Model Random Forest berhasil dilatih.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b33f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81270146",
   "metadata": {},
   "source": [
    "## **6. Evaluation**\n",
    "Evaluasi performa kedua model menggunakan berbagai metrik pada data uji. Fungsi evaluasi yang sama akan digunakan untuk memastikan perbandingan yang adil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3bbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengevaluasi model dan menampilkan hasilnya\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Menghitung metrik evaluasi\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Menampilkan hasil\n",
    "    print(f\"--- Evaluasi Model: {model_name} ---\")\n",
    "    print(f\"Akurasi: {accuracy:.3f}\")\n",
    "    print(f\"Presisi: {precision:.3f}\")\n",
    "    print(f\"Recall: {recall:.3f}\")\n",
    "    print(f\"F1-Score: {f1:.3f}\\n\")\n",
    "    \n",
    "    # Menampilkan Laporan Klasifikasi\n",
    "    print(\"Laporan Klasifikasi:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Sehat', 'Gagal Jantung']))\n",
    "    \n",
    "    # Menampilkan Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Sehat', 'Gagal Jantung'],\n",
    "                yticklabels=['Sehat', 'Gagal Jantung'])\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Prediksi')\n",
    "    plt.ylabel('Aktual')\n",
    "    plt.show()\n",
    "    \n",
    "    return {'Akurasi': accuracy, 'Presisi': precision, 'Recall': recall, 'F1-Score': f1}\n",
    "\n",
    "# Mengevaluasi kedua model pipeline\n",
    "log_reg_metrics = evaluate_model(log_reg_pipeline, X_test, y_test, \"Logistic Regression\")\n",
    "rand_forest_metrics = evaluate_model(rand_forest_pipeline, X_test, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041285d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11bceaf9",
   "metadata": {},
   "source": [
    "## **7. Perbandingan Hasil dan Kesimpulan**\n",
    "Membandingkan metrik evaluasi dari kedua model untuk menentukan model mana yang memberikan performa terbaik untuk kasus prediksi gagal jantung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2071cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat DataFrame untuk membandingkan metrik dari kedua model\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Logistic Regression': log_reg_metrics,\n",
    "    'Random Forest': rand_forest_metrics\n",
    "}).T # .T untuk transpose (menukar baris dan kolom)\n",
    "\n",
    "print(\"Perbandingan Metrik Evaluasi:\")\n",
    "display(metrics_df.round(3))\n",
    "\n",
    "# Menentukan model terbaik berdasarkan F1-Score\n",
    "best_model_name = metrics_df['F1-Score'].idxmax()\n",
    "print(f\"\\nKesimpulan: Model terbaik berdasarkan F1-Score adalah **{best_model_name}**.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc69be2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
